{
	"runtime": {
		"pool_size": 1,
		"per_request_timeout_s": 0
	},
	"memory": {
		"strategies": {
			"thread_window": {
				"max_context_tokens": 8192
			}
		}
	},
	"models": [

		{
			"active": false,
			"name": "Qwen 2.5 7B Instruct Q8",
			"path": "/agent_server/app/data/models/qwen2.5-7b-instruct-q8_0-00001-of-00003.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.9,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 2048
			}
		},	

		{
			"active": false,
			"name": "Gemma 3n E4B it Q8",
			"path": "/agent_server/app/data/models/gemma-3n-E4B-it-Q8_0.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 4096,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.7,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 512
			}
		},

		{
			"active": false,
			"name": "EuroLLM 22B Instruct 2512 Q4 KM",
			"path": "/agent_server/app/data/models/EuroLLM-22B-Instruct-2512.Q4_K_M.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.7,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 2048
			}
		},

		{
			"active": false,
			"name": "Phi-4 Q8",
			"path": "/agent_server/app/data/models/phi-4-Q8_0.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.7,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 2048
			}
		},

		{
			"active": false,
			"name": "Phi-4 Q5_KL",
			"path": "/agent_server/app/data/models/phi-4-Q5_K_L.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 4096,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.7,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 512
			}
		},		
		
		{
			"active": false,
			"name": "Phi-4 Mini Instruct Q8",
			"path": "/agent_server/app/data/models/phi-4-mini-instruct-Q8_0.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 4096,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"n_batch": 512,
				"n_ubatch": 512,
				"temperature": 0.7,
				"top_k": 40,
				"top_p": 0.95,
				"min_p": 0.0,
				"max_tokens": 512
			}
		},

		{
			"active": false,
			"name": "Jan Nano 128k Q4 K M",
			"path": "/agent_server/app/data/models/jan-nano-128k-Q4_K_M.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"temperature": 0.6,
				"top_k": 40,
				"top_p": 0.9,
				"min_p": 0.1,
				"max_tokens": 512
			}
		},

		{
			"active": false,
			"name": "Smol VLM2 2.2B Instruct Q8",
			"path": "/agent_server/app/data/models/SmolVLM2-2.2B-Instruct.Q8_0.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"temperature": 0.6,
				"top_k": 40,
				"top_p": 0.9,
				"min_p": 0.1,
				"max_tokens": 512
			}
		},

		{
			"active": true,
			"name": "Smol LLM2 135M Instruct Q8",
			"path": "/agent_server/app/data/models/SmolLM2-135M-Instruct-Q8_0.gguf",
			"system_prompt": "",
			"params": {
				"n_ctx": 8192,
				"n_threads": 0,
				"n_gpu_layers": -1,
				"temperature": 0.6,
				"top_k": 40,
				"top_p": 0.9,
				"min_p": 0.1,
				"max_tokens": 512
			}
		}

	]
}
